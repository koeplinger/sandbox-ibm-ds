{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Car ride-share potential in mid-size U.S. cities from geographic spread\n\n## (notebook 3: city template)\n\nThird notebook for the IBM Data Science Specialization on Coursera, which contains the consolidated methods and functions from the first two notebooks, to serve as a template to be used per-city.\n\n", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Installs (if needed) and imports\n\nSee notesbooks 1 and 2 for details.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import pandas as pd\nimport numpy as np\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\nimport math\nimport json\n\ntry:\n    from geopy.geocoders import Nominatim\n    print(Nominatim)\nexcept:\n    !conda install -c conda-forge geopy=1.18.1 --yes\n    \nfrom geopy.geocoders import Nominatim\nfrom pandas.io.json import json_normalize\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\ntry:\n    import folium\n    print(folium)\nexcept:\n    !conda install -c conda-forge folium=0.8.0 --yes\n    \nimport folium\nimport time\n    \ntry:\n    import pandas_profiling\n    print(pandas_profiling)\nexcept:\n    !conda install -c conda-forge pandas-profiling=1.4.1 --yes\n    \nimport pandas_profiling", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Foursquare secret", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# (paste secret from local file)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "print('CLIENT_ID set: {}'.format(CLIENT_ID is not None))\nprint('CLIENT_SECRET set: {}'.format(CLIENT_SECRET is not None))\n\nVERSION = '20180605' # Foursquare API version", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Which city?", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "CITY_INDEX=0\nRADIUS=800\nMAX_COORDS=1000\nMAP_ZOOM_LEVEL=11\nMARKER_ZOOM=0.1", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## All function definitions\n\nSee notebooks 1 and 2 for details.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "print('Starting: Get list of cities')\n\nurl = 'https://en.wikipedia.org/w/index.php?title=List_of_United_States_cities_by_population&oldid=883568308'\nwebsite_url = requests.get(url).text\nsoup = BeautifulSoup(website_url, 'lxml')\ncity_table = soup.find('table', { 'class' : 'wikitable sortable' })\n\nprint('---------CITIES TABLE (raw)')\nprint(\"{}\\n\\n   [...]\\n\\n{}\".format(str(city_table)[:500].replace('\\n', '').replace('<tr>', '\\n\\n<tr>'), str(city_table)[-500:]))\n\n\nl = []\n\ntable_rows = city_table.find_all('tr')\nfor tr in table_rows:\n    td = tr.find_all('td')\n    row = [tr.text.strip() for tr in td]\n    if len(row) < 1:\n        print(\"(ignoring empty row)\")\n        test_size = 0\n    else:\n        test_size = int(row[3].replace(',', ''))\n        \n    if test_size >= 300000 and test_size <= 400000:\n        city_name = re.sub('\\[.*\\]', '', row[1])\n        city_state = row[2]\n        city_estd_pop2017 = test_size\n        city_latlongraw = re.sub('^.*/', '', re.sub('\\(.*\\)', '', row[10])).replace(' ', '')\n        # strip non-ASCII residue\n        city_latlongraw = city_latlongraw.encode('ascii',errors='ignore').decode()\n        city_lat = float(re.sub(';.*$', '', city_latlongraw))\n        city_long = float(re.sub('^.*;', '', city_latlongraw))\n        l.append([city_name, city_state, city_estd_pop2017, city_lat, city_long])\n\ncities_df = pd.DataFrame(l)\ncities_df.columns = ['City name', 'City state', 'Population', 'Latitude', 'Longitude']\n\nprint('----------CITIES DATAFRAME')\nprint(cities_df)\n\n\ndef getVenuesNearLatLong(latitude, longitude, radius=500, limit=100, verbose=True):\n    \n    venues_list=[]\n                \n    # create the API request URL\n    url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION,\n            latitude, \n            longitude, \n            radius, \n            limit)\n            \n    # make the GET request (on error try four more times before giving up)\n    num_tries = 0\n    results = [] # assume no venues if persistent error\n    \n    while num_tries < 5:\n        num_tries +=1\n        try:\n            results_raw = requests.get(url)\n            results = results_raw.json()[\"response\"]['groups'][0]['items']\n        except:\n            print('(err)', end='')\n            time.sleep(2) # sleep for two seconds, then retry\n        \n    # return only relevant information for each nearby venue\n    venues_list.append([(\n            latitude, \n            longitude, \n            v['venue']['name'], \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    if (len(results) > 0):\n        nearby_venues.columns = [\n                  'Latitude', \n                  'Longitude', \n                  'Venue', \n                  'Venue Category']\n    \n    if verbose:\n        print('found {} venues within {} meters of {}/{}'.format(len(results), radius, latitude, longitude))\n    else:\n        print('{}'.format(len(results)), end='. ')\n    \n    return(nearby_venues)\n\n\ndef get_venues_in_hex_grid(latitude, longitude, venues_dict, this_coord, radius=500, limit=100, new_coords=[], verbose=True):\n    '''\n    Calls Foursquare in a hex grid around a given coordinate point. If venues\n    have already been searched on one of the hex grid points, that result is\n    kept and no new search is executed.\n    \n    Parameters:\n    \n    latitude and longitude are as of the origin coordinate (0, 0),\n    venues_dict are the venues found so far (dictionary keys are a coordinate tuple),\n    this_coord is the center coordinate around which the hex grid is to be searched,\n    radius is the radius [meters] to search around a coordinate point,\n    limit is the maximum number of venues to return from a Foursquare search.\n    new_coords is a list of coordinate points that wasn't probed yet\n    \n    Returns a list of new coordinate tuples appended to the new_coords parameter, if any\n    '''\n    \n    r_earth = 6378000. # approximate radius of the Earth in meters\n    pi = math.pi\n    sqrt_three = math.sqrt(3.)\n    overlap = 1.4 # 40% overlap\n    \n    cx = this_coord[0] # center X\n    cy = this_coord[1] # center Y\n    hex_coords = [ (cx-1,cy), (cx+1, cy), (cx,cy-1), (cx,cy+1), (cx-1,cy+1), (cx+1,cy-1) ] # the gex grid around this_coord\n    \n    if (cx, cy) in new_coords:\n        new_coords.remove((cx, cy))\n    \n    for this_hex in hex_coords:\n        if not this_hex in venues_dict:\n            # the coordinate has not been searched for\n            \n            # get the x- and y-step from a hex grid; start with a square grid (letting the circles overlap a bit):\n            dx_square = this_hex[0] * radius * ( overlap / 2. )\n            dy_square = this_hex[1] * radius * ( overlap / 2. )\n            # now convert to a hex grid:\n            dx = dx_square + dy_square / 2.\n            dy = dy_square * ( sqrt_three / 2. )\n            # approximate the center point's latitude and longitude assuming locally flat Earth\n            hex_latitude  = latitude  + (dy / r_earth) * (180 / pi);\n            hex_longitude = longitude + (dx / r_earth) * (180 / pi) / math.cos(latitude * pi/180);\n            \n            if verbose:\n                print('getting coordinate {}...'.format(this_hex))\n            else:\n                print('({},{}):'.format(this_hex[0], this_hex[1]), end='')\n                \n            this_venues = getVenuesNearLatLong(hex_latitude, hex_longitude, radius=radius, limit=limit, verbose=verbose)\n            venues_dict[this_hex] = this_venues\n            if not this_hex in new_coords:\n                new_coords.append(this_hex)\n    \n    return new_coords\n\n\ndef make_map_from_dict(lat_orig, long_orig, venues_dict, zoom_start,\n                       city_name='(city_name)', city_state='(city_state)',\n                       radius_zoom=1.0, width=600, height=600,\n                       no_touch=True,\n                       zoom_control=False,\n                       failsafe_abort_num=4000,\n                       simple_rendering=False):\n    \n    if zoom_control == False:\n        min_zoom = zoom_start\n        max_zoom = zoom_start\n    else:\n        min_zoom = 0\n        max_zoom = 16\n    \n    new_map = folium.Map(\n        location=[lat_orig, long_orig],\n        zoom_start=zoom_start,\n        width=width,\n        height=height,\n        control_scale=True,\n        no_touch=no_touch,\n        min_zoom=min_zoom,\n        max_zoom=max_zoom\n    )\n    \n    num_markers=0\n\n    # add markers to map\n    for coords, venues in venues_dict.items():\n        num_markers += 1\n        if (venues.shape[0] > 0) and (num_markers < failsafe_abort_num): \n            if simple_rendering:\n                folium.Circle(\n                    [venues['Latitude'][0], venues['Longitude'][0]],\n                    radius=venues.shape[0] * radius_zoom,\n                    color=None,\n                    fill=True,\n                    fill_color='#005090',\n                    fill_opacity=0.7).add_to(new_map)\n            else:\n                label = '{}, # venues: {}'.format(coords, venues.shape[0])\n                label = folium.Popup(label, parse_html=True)\n                folium.CircleMarker(\n                    [venues['Latitude'][0], venues['Longitude'][0]],\n                    radius=venues.shape[0] * radius_zoom,\n                    popup=label,\n                    color='blue',\n                    fill=True,\n                    fill_color='#3186cc',\n                    fill_opacity=0.7,\n                    parse_html=False).add_to(new_map)\n        \n    legend_html = ('<div style=\"position: fixed; top: 30px; left: 50px; width: 450px;' \n                + 'height: 30px; border: 2px solid grey; z-index: 9999; font-size: 16px; background-color: white\">' \n                + '&nbsp;{},&nbsp;{}' \n                + '</div>').format(\n                     city_name,\n                     city_state\n                     )\n    new_map.get_root().html.add_child(folium.Element(legend_html))\n     \n    return new_map\n\n\ndef find_venues_geo_distribution(cities_df, city_index, max_coords_tested=100, radius=1500, limit=100, verbose=True):\n    \n    city_name = cities_df['City name'][city_index]\n    city_state = cities_df['City state'][city_index]\n    \n    # initialize venues_dict with the venues dataframe at the origin\n    venues_dict = {}\n    origin_coord = (0,0)\n    lat_orig = cities_df.Latitude[city_index]\n    long_orig = cities_df.Longitude[city_index]\n    print('[test #1 of {}] (0,0):'.format(max_coords_tested), end='')\n    venues_df = getVenuesNearLatLong(lat_orig, long_orig, radius=radius, verbose=verbose)\n    venues_dict[origin_coord] = venues_df\n    \n    # mark the origin as the first (and only) coordinate point not yet explored\n    new_coords = [(0, 0)]\n    num_coords_tested = 1\n    \n    while num_coords_tested < max_coords_tested:\n        \n        highest_venues = -1\n        new_test_coord = None\n        \n        for this_coord in new_coords:\n            venues_df = venues_dict[this_coord]\n            if venues_df.shape[0] > highest_venues:\n                new_test_coord = this_coord\n                highest_venues = venues_df.shape[0]\n        \n        # call the hex grid exploration function\n        num_coords_tested += 1\n        print('[test #{} of {}]'.format(num_coords_tested, max_coords_tested), end=' ')\n        new_coords = get_venues_in_hex_grid(lat_orig, long_orig, venues_dict, new_test_coord, radius=radius, new_coords=new_coords, limit=limit, verbose=verbose )\n        \n    return lat_orig, long_orig, venues_dict, city_name, city_state\n\n\ndef is_indicator_venue(venue_type):\n    if venue_type is None:\n        return False\n    \n    magic_words = [\n        'yoga',\n        'salad',\n        'coworking',\n        'alternative',\n        'bike',\n        'fitness',\n        'running',\n        'jogging',\n        'cycling',\n        'cycle',\n        'athletics',\n        'gluten',\n        'health',\n        'recreation',\n        'tennis',\n        'vegetarian',\n        'vegan',\n        'tennis',\n        'disc golf',\n        'pilates',\n        'share',\n        'sharing',\n        'incubat',\n        'innovat'\n    ]\n    return any(substring in venue_type.lower() for substring in magic_words)\n\nprint('Perform some tests on indicator venues:')\nprint(is_indicator_venue(None))\nprint(is_indicator_venue(''))\nprint(is_indicator_venue('Salad Bar'))\nprint(is_indicator_venue('Chinese Restaurant'))\nprint(is_indicator_venue('Coworking space'))\n\n\ndef aggregate_venues_dict(venues_dict):\n    venues_agg = []\n    venues_types = []\n    for coord, venues in venues_dict.items():\n        num_venues = venues.shape[0]\n        num_indicators = 0\n        if num_venues > 0:\n            for this_type in venues['Venue Category'].values:\n                venues_types.append(this_type)\n                if is_indicator_venue(this_type):\n                    num_indicators += 1\n        venues_agg.append([coord, num_venues, num_indicators])\n    venues_agg_df = pd.DataFrame(venues_agg)\n    venues_agg_df.columns = ['coord', 'num_venues', 'num_indicators']\n    return venues_agg_df, set(venues_types)\n\n\ndef find_venues_distance_to_center(venues_agg_df):\n    '''\n    Appends or updates x/y and distance-to-center columns of venues_agg_df.\n    Also returns some aggregates that were calculated along the way.\n    '''\n    \n    x, y = zip(*venues_agg_df['coord'])\n    total_num_venues = venues_agg_df['num_venues'].sum()\n    total_num_indicators = venues_agg_df['num_indicators'].sum()\n    center_x = ( x * venues_agg_df['num_venues'] ).sum() / total_num_venues\n    center_y = ( y * venues_agg_df['num_venues'] ).sum() / total_num_venues\n    dx = x - center_x\n    dy = y - center_y\n    dist2 = dx * dx + dy * dy\n    venues_agg_df['dist'] = np.sqrt(dist2)\n    \n    return center_x, center_y, total_num_venues, total_num_indicators\n\n\ndef gather_distance_distribution_stats(venues_agg_df, city_index=-1, city_display='(city name, state)', return_as_list_append_string=False):\n    \n    center_x, center_y, total_num_venues, total_num_indicators = find_venues_distance_to_center(venues_agg_df)\n    num_venues_per_coord = venues_agg_df['num_venues']\n    dist_per_coord = venues_agg_df['dist']\n    \n    # blow up the dist_per_coord series by the nunmber of venues at the coordinate\n    \n    dist_list = []\n    for this_coord in zip(num_venues_per_coord, dist_per_coord):\n        this_list = [float(this_coord[1])] * int(this_coord[0])\n        dist_list.extend(this_list)\n    \n    dist_list_df = pd.DataFrame(dist_list)\n    dist = dist_list_df[0]\n    \n    # now perform statistics on that new list\n    \n    mean = dist.mean()\n    std = dist.std()\n    p25 = dist.quantile(0.25)\n    median = dist.quantile(0.5)\n    p75 = dist.quantile(0.75)\n    max_d = dist.max()\n    iqr = p75 - p25\n    kurt = dist.kurtosis() # \"peaky-ness\"\n    mad = dist.mad() # mean absolute deviation\n    skew = dist.skew() # skewedness\n    \n    if return_as_list_append_string:\n        retS = '# Create list at the beginning:\\n'\n        retS += '#     l = []\\n\\n'\n        retS += 'l.append(['\n        retS += '{}, \"{}\", ({:.2f}, {:.2f}), '.format(city_index, city_display, center_x, center_y)\n        retS += '{}, {}, {}, {}, '.format(total_num_venues, total_num_indicators, mean, std)\n        retS += '{}, {}, {}, {}, '.format(p25, median, p75, max_d)\n        retS += '{}, {}, {}, {}'.format(iqr, kurt, mad, skew)\n        retS += '])\\n\\n'\n        retS += '# Convert list to pandas DataFrame:\\n'\n        retS += '#     cities_stats_df = pd.DataFrame(l)\\n'\n        retS += '#     cities_stats_df.columns = ['\n        retS += '\"city index\", \"city name, state\", \"center coord\", \"total num venues\", \"total num indicators\", '\n        retS += '\"mean distance to center\", \"std dev\", \"25th percentile\", \"median\", \"75th percentile\", \"max distance to center\", '\n        retS += '\"interquartile range\", \"kurtosis\", \"mean absolute deviation\", \"skewedness\"'\n        retS += ']\\n'\n        return retS\n\n    else:\n        return center_x, center_y, total_num_venues, total_num_indicators, \\\n               mean, std, p25, median, p75, max_d,                         \\\n               iqr, kurt, mad, skew\n    \n\n    \n\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## Quick test", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "lat_orig, long_orig, venues_dict, city_name, city_state = find_venues_geo_distribution(\n    cities_df, city_index=CITY_INDEX, radius=RADIUS, max_coords_tested=10, verbose=False)\n\nprint(\"{}, {}\\n\".format(city_name, city_state))\n\nvenues_agg_df, venues_types = aggregate_venues_dict(venues_dict)\n\nprint(\"\\n{}\\n\".format(venues_agg_df.head(10)))\n\ncenter_x, center_y, total_num_venues, total_num_indicators, \\\n           mean, std, p25, median, p75, max_d,                         \\\n           iqr, kurt, mad, skew \\\n    = gather_distance_distribution_stats(venues_agg_df)\n\nprint(center_x, center_y, total_num_venues, total_num_indicators, \\\n           mean, std, p25, median, p75, max_d,                         \\\n           iqr, kurt, mad, skew)\n\nlist_append_string = gather_distance_distribution_stats(\n    venues_agg_df,\n    city_index=CITY_INDEX,\n    city_display='{}, {}'.format(city_name, city_state),\n    return_as_list_append_string=True)\n\nprint('\\nlist_append_string:\\n\\n{}'.format(list_append_string))\n\nmake_map_from_dict(\n    lat_orig, long_orig, venues_dict, 13, city_name, city_state, radius_zoom=7,\n    width=600, height=600, simple_rendering=True)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## The real deal", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "lat_orig, long_orig, venues_dict, city_name, city_state = find_venues_geo_distribution(\n    cities_df, city_index=CITY_INDEX, radius=RADIUS, max_coords_tested=MAX_COORDS, verbose=False)\n\nprint(\"\\n\\n{}, {}\\n\".format(city_name, city_state))\nvenues_agg_df, venues_types = aggregate_venues_dict(venues_dict)\nprint('Total shape: {}\\n\\nSample 10 venues per coordinate (unsorted):'.format(venues_agg_df.shape))\nprint('{}\\n'.format(venues_agg_df.head(10)))\n\nlist_append_string = gather_distance_distribution_stats(\n    venues_agg_df,\n    city_index=CITY_INDEX,\n    city_display='{}, {}'.format(city_name, city_state),\n    return_as_list_append_string=True)\n\nprint('\\nResulting list append string for this city:\\n\\n{}'.format(list_append_string))\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "make_map_from_dict(\n    lat_orig, long_orig, venues_dict, 11, city_name, city_state, radius_zoom=7,\n    width=600, height=600, simple_rendering=True)\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}