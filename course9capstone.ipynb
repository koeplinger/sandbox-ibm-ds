{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# IBM Data Science Specialization Course 9\n\nThis notebook will be mainly used for the capstone project.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "import pandas as pd\nimport numpy as np\n\nprint('Hello Capstone Project Course!')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Hello Capstone Project Course!\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "# Course 9 week 3 assignment: Toronto\n\nScrape the Wikipedia table at https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M (retrieved 24 Feb 2019) into a pandas DataFrame.\n\n## First try: parse Wikipedia using py-wikimarkup\n\nInitial how-to instructions from https://stackoverflow.com/questions/15724034/how-to-convert-wikipedia-wikitable-to-python-pandas-dataframe (retrieved 24 Feb 2019).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!pip install py-wikimarkup\n!pip install pyquery", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting py-wikimarkup\n  Downloading https://files.pythonhosted.org/packages/a2/b3/32fc3f60c4b39720d9ba2de139049913ac22f8a75a5abb5d33d404492e87/py-wikimarkup-1.0.2.tar.gz\nBuilding wheels for collected packages: py-wikimarkup\n  Running setup.py bdist_wheel for py-wikimarkup ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/50/a3/eb/47f4014d6bd8d2d233b552150d8ba308299cdf0bd2046ddd91\nSuccessfully built py-wikimarkup\nInstalling collected packages: py-wikimarkup\nSuccessfully installed py-wikimarkup-1.0.2\nCollecting pyquery\n  Downloading https://files.pythonhosted.org/packages/09/c7/ce8c9c37ab8ff8337faad3335c088d60bed4a35a4bed33a64f0e64fbcf29/pyquery-1.4.0-py2.py3-none-any.whl\nRequirement not upgraded as not directly required: lxml>=2.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pyquery)\nCollecting cssselect>0.7.9 (from pyquery)\n  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\nInstalling collected packages: cssselect, pyquery\nSuccessfully installed cssselect-1.0.3 pyquery-1.4.0\n"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "import wikimarkup\nimport pandas as pd\nfrom pyquery import PyQuery\n\ndef get_tables(wiki):\n    html = PyQuery(wikimarkup.parse(wiki))\n    frames = []\n    for table in html('table'):\n        data = [[x.text.strip() for x in row]\n                for row in table.getchildren()]\n        df = pd.DataFrame(data[1:], columns=data[0])\n        frames.append(df)\n    return frames\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "cannot import name 'parse'", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-3-72736056bb72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwikimarkup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyquery\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyQuery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/wikimarkup/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparselite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregisterTagHook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;31mImportError\u001b[0m: cannot import name 'parse'"
                    ], 
                    "ename": "ImportError"
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "Unfortunately, a pre-installed \"parse\" package in IBM Watson Studio conflicts with the \"parse.py\" file name inside wikimarkup.\n\n## Second try: parse Wikipedia using BeautifulSoup\n\nFollowing https://medium.com/analytics-vidhya/web-scraping-wiki-tables-using-beautifulsoup-and-python-6b9ea26d8722 (retrieved 24 Feb 2019)\n\nGettin HTML of the Wikipedia page:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import requests\nurl = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\nwebsite_url = requests.get(url).text\n\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(website_url, 'lxml')\nprint(\"{}\\n\\n   [...]\\n\\n{}\".format(soup.prettify()[:500], soup.prettify()[-500:]))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<!DOCTYPE html>\n<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n <head>\n  <meta charset=\"utf-8\"/>\n  <title>\n   List of postal codes of Canada: M - Wikipedia\n  </title>\n  <script>\n   document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );\n  </script>\n  <script>\n   (window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"List_of_po\n\n   [...]\n\n:\"Contributors to Wikimedia projects\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Wikimedia Foundation, Inc.\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png\"}},\"datePublished\":\"2004-03-20T10:02:13Z\",\"dateModified\":\"2019-01-04T18:32:45Z\",\"headline\":\"Wikimedia list article\"}\n  </script>\n  <script>\n   (window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgBackendResponseTime\":113,\"wgHostname\":\"mw1329\"});});\n  </script>\n </body>\n</html>\n\n"
                }
            ], 
            "execution_count": 12
        }, 
        {
            "source": "This library seems to function OK.\n\nThe needed data is contained in the first (and only) table, and is rendered with HTML style \"wikitable sortable\". Parse it:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "My_table = soup.find('table', { 'class' : 'wikitable sortable' })\nprint(\"{}\\n\\n   [...]\\n\\n{}\".format(str(My_table)[:500], str(My_table)[-500:]))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<table class=\"wikitable sortable\">\n<tbody><tr>\n<th>Postcode</th>\n<th>Borough</th>\n<th>Neighbourhood\n</th></tr>\n<tr>\n<td>M1A</td>\n<td>Not assigned</td>\n<td>Not assigned\n</td></tr>\n<tr>\n<td>M2A</td>\n<td>Not assigned</td>\n<td>Not assigned\n</td></tr>\n<tr>\n<td>M3A</td>\n<td><a href=\"/wiki/North_York\" title=\"North York\">North York</a></td>\n<td><a href=\"/wiki/Parkwoods\" title=\"Parkwoods\">Parkwoods</a>\n</td></tr>\n<tr>\n<td>M4A</td>\n<td><a href=\"/wiki/North_York\" title=\"North York\">North York</a></td>\n<td>\n\n   [...]\n\n/Etobicoke\" title=\"Etobicoke\">Etobicoke</a></td>\n<td><a href=\"/wiki/The_Queensway\" title=\"The Queensway\">The Queensway West</a>\n</td></tr>\n<tr>\n<td>M8Z</td>\n<td><a href=\"/wiki/Etobicoke\" title=\"Etobicoke\">Etobicoke</a></td>\n<td>Royal York South West\n</td></tr>\n<tr>\n<td>M8Z</td>\n<td><a href=\"/wiki/Etobicoke\" title=\"Etobicoke\">Etobicoke</a></td>\n<td><a href=\"/wiki/Bloor\" title=\"Bloor\">South of Bloor</a>\n</td></tr>\n<tr>\n<td>M9Z</td>\n<td>Not assigned</td>\n<td>Not assigned\n</td></tr>\n</tbody></table>\n"
                }
            ], 
            "execution_count": 14
        }, 
        {
            "source": "## Clean data for postal code, borough, and neighborhood\n\nNow loop through all rows from that table. For each row:\n1. Ignore if it is the header row (no \"TD\" tags),\n2. strip leading and trailing whitespace (including line breaks),\n3. Ignore if the borough is \"Not assigned\",\n4. If the borough is given but neighborhoos is \"Not assigned\", fill in the borough as neighborhood name.\nFinally, build a new pandas DataFrame from the list items collected.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "l = []\nunassigned_pc = []\n\ntable_rows = My_table.find_all('tr')\nfor tr in table_rows:\n    td = tr.find_all('td')\n    row = [tr.text.strip() for tr in td]\n    if len(row) < 1:\n        print(\"ignoring empty row\")\n    elif row[1] == 'Not assigned':\n        unassigned_pc.append(row[0])\n    else:\n        if row[2] == 'Not assigned':\n            row[2] = row[1]\n            print('assigning neighborhood same as borough: {}'.format(row[2]))\n        l.append(row)\n\nprint(\"ignoring unassigned postal codes:{}\".format(unassigned_pc))\n        \nMy_df = pd.DataFrame(l, columns=[\"PostalCode\", \"Borough\", \"Neighborhood\"])\nMy_df.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "ignoring empty row\nassigning neighborhood same as borough: Queen's Park\nignoring unassigned postal codes:['M1A', 'M2A', 'M8A', 'M2B', 'M7B', 'M8B', 'M2C', 'M7C', 'M8C', 'M2E', 'M3E', 'M7E', 'M8E', 'M9E', 'M2G', 'M3G', 'M7G', 'M8G', 'M9G', 'M7H', 'M8H', 'M9H', 'M7J', 'M8J', 'M9J', 'M7K', 'M8K', 'M9K', 'M7L', 'M8L', 'M7M', 'M8M', 'M7N', 'M8N', 'M3P', 'M7P', 'M8P', 'M3R', 'M8R', 'M2S', 'M3S', 'M7S', 'M8S', 'M9S', 'M2T', 'M3T', 'M6T', 'M7T', 'M8T', 'M9T', 'M2V', 'M3V', 'M6V', 'M7V', 'M2W', 'M3W', 'M6W', 'M7W', 'M2X', 'M3X', 'M6X', 'M7X', 'M9X', 'M1Y', 'M2Y', 'M3Y', 'M5Y', 'M6Y', 'M9Y', 'M1Z', 'M2Z', 'M3Z', 'M4Z', 'M5Z', 'M6Z', 'M7Z', 'M9Z']\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PostalCode</th>\n      <th>Borough</th>\n      <th>Neighborhood</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M3A</td>\n      <td>North York</td>\n      <td>Parkwoods</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M4A</td>\n      <td>North York</td>\n      <td>Victoria Village</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Harbourfront</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M5A</td>\n      <td>Downtown Toronto</td>\n      <td>Regent Park</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M6A</td>\n      <td>North York</td>\n      <td>Lawrence Heights</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  PostalCode           Borough      Neighborhood\n0        M3A        North York         Parkwoods\n1        M4A        North York  Victoria Village\n2        M5A  Downtown Toronto      Harbourfront\n3        M5A  Downtown Toronto       Regent Park\n4        M6A        North York  Lawrence Heights"
                    }, 
                    "execution_count": 25, 
                    "metadata": {}
                }
            ], 
            "execution_count": 25
        }, 
        {
            "source": "## Aggregate neighborhoods by borough and postal code\n\nConcatenate neighborhoods grouped by postal code and borough.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df_grouped = My_df.groupby(['PostalCode', 'Borough'])['Neighborhood'].apply(lambda x: \"%s\" % ', '.join(x)).reset_index()\ndf_grouped.head()", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Result: Number of rows in Toronto neighborhood DataFrame", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "print(\"Numver of records in cleaned, aggregated Toronto neighborhoods scraped from Wikipedia:\")\nprint(\"df.shape={},\\nnumber of rows={}\".format(df_grouped.shape, df_grouped.shape[0]))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Numver of records in cleaned, aggregated Toronto neighborhoods scraped from Wikipedia:\ndf.shape=(103, 3),\nnumber of rows=103\n"
                }
            ], 
            "execution_count": 45
        }, 
        {
            "source": "!pip install geocoder", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Requirement not upgraded as not directly required: geocoder in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages\nRequirement not upgraded as not directly required: six in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from geocoder)\nRequirement not upgraded as not directly required: requests in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from geocoder)\nRequirement not upgraded as not directly required: future in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from geocoder)\nRequirement not upgraded as not directly required: click in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from geocoder)\nRequirement not upgraded as not directly required: ratelim in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from geocoder)\nRequirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->geocoder)\nRequirement not upgraded as not directly required: idna<2.7,>=2.5 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->geocoder)\nRequirement not upgraded as not directly required: urllib3<1.23,>=1.21.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->geocoder)\nRequirement not upgraded as not directly required: certifi>=2017.4.17 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->geocoder)\nRequirement not upgraded as not directly required: decorator in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ratelim->geocoder)\n"
                }
            ], 
            "execution_count": 46
        }, 
        {
            "source": "import geocoder # import geocoder\n\n# testing geocoder\nlat_lng_coords = None\ncnt = 0\n\n# loop until you get the coordinates\nwhile(lat_lng_coords is None and cnt < 20):\n    print('attempt {}'.format(cnt))\n    cnt += 1\n    g = geocoder.google('Toronto, Canada')\n    lat_lng_coords = g.latlng\n\nif lat_lng_coords is None:\n    print('API calls unsuccessful')\nelse:\n    latitude = lat_lng_coords[0]\n    longitude = lat_lng_coords[1]\n    print(\"{} / {}\".format(latitude, longitude))\n", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "attempt 0\nattempt 1\nattempt 2\nattempt 3\nattempt 4\nattempt 5\nattempt 6\nattempt 7\nattempt 8\nattempt 9\nattempt 10\nattempt 11\nattempt 12\nattempt 13\nattempt 14\nattempt 15\nattempt 16\nattempt 17\nattempt 18\nattempt 19\nAPI calls unsuccessful\n"
                }
            ], 
            "execution_count": 47
        }, 
        {
            "source": "## TODO continue here", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 48
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}